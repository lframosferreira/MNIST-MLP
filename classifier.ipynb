{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.typing as npt\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining constants\n",
    "TEST_SIZE: np.float_ = .3\n",
    "RANDOM_STATE: np.int_ = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(label: np.int_, pixels: npt.NDArray[np.int_]) -> None:\n",
    "    plt.title(f\"True label: {int(label)}\")\n",
    "    plt.imshow(np.reshape(pixels, (28, 28)), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  775  776  777  778   \n",
       "0    7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  \\\n",
       "1    2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2    1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3    0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4    4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing and handling data\n",
    "data: pd.DataFrame = pd.read_csv(\"data/input/data_tp1\", header=None)\n",
    "data.iloc[:, data.columns != 0] = data.iloc[:, data.columns != 0] / 255\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNIST_MLP(data: npt.NDArray[np.int_], hidden_layer_size: np.int_, batch_size: np.int_, learning_rate: np.int_) -> dict:\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(784,)),\n",
    "        tf.keras.layers.Dense(hidden_layer_size, activation=\"sigmoid\"),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    input_data: npt.NDArray[np.int_] = data[:, 1:]\n",
    "    labels: npt.NDArray[np.int_] = data[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_data, labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    metrics = [\"accuracy\"]\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    epochs: np.int_ = 10\n",
    "\n",
    "    model_history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=0)\n",
    "\n",
    "    y_pred: npt.NDArray[np.int_] = model.predict(X_test, batch_size=batch_size, verbose=0)\n",
    "    y_pred = y_pred.argmax(axis=-1)\n",
    "\n",
    "    accuracy_score: np.float_ = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "    precision_score: npt.NDArray[np.float_] = sklearn.metrics.precision_score(y_test, y_pred, average=None, zero_division=0)\n",
    "    recall_score: npt.NDArray[np.float_] = sklearn.metrics.recall_score(y_test, y_pred, average=None, zero_division=0)\n",
    "    f1_score: npt.NDArray[np.float_] = sklearn.metrics.f1_score(y_test, y_pred, average=None)\n",
    "    confusion_matrix: npt.NDArray[np.int_] = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    run_info: dict = {\n",
    "        \"accuracy_score\": accuracy_score,\n",
    "        \"precision_score\": precision_score.tolist(),\n",
    "        \"recall_score\": recall_score.tolist(),\n",
    "        \"f1_score\": f1_score.tolist(),\n",
    "        \"confusion_matrix\": confusion_matrix.tolist(),\n",
    "        \"random_state_seed\": RANDOM_STATE,\n",
    "        \"test_size\": TEST_SIZE,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate\n",
    "    }\n",
    "\n",
    "    return run_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes: npt.NDArray[np.int_] = np.array([(25,), (50,), (100,)])\n",
    "batch_sizes: list[int] = [1, 20, 50, 3500]\n",
    "lerning_rates: npt.NDArray[np.float_] = np.array([0.5, 1.0, 10.0])\n",
    "\n",
    "configurations: list = list(itertools.product(hidden_layer_sizes, batch_sizes, lerning_rates))\n",
    "\n",
    "run_infos: list[dict] = [MNIST_MLP(data=data.to_numpy(), hidden_layer_size=a, batch_size=b, learning_rate=c) for a, b, c in configurations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/results.json\", \"a\") as file:\n",
    "    json.dump([run_info for run_info in run_infos], file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>random_state_seed</th>\n",
       "      <th>test_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.100667</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.100...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0059171597633130004, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.011764705882352, 0.0, 0...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 125, 0], [0, 0, 0, 0...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.132667</td>\n",
       "      <td>[0.0, 1.0, 0.095899930507296, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.0, 0.37423312883435506, 1.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.5446428571428571, 0.175015852885225, 0...</td>\n",
       "      <td>[[0, 0, 125, 0, 0, 0, 0, 0, 0, 0], [0, 61, 102...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.137333</td>\n",
       "      <td>[0.0, 0.875, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.0, 0.386503067484662, 0.007246376811594001,...</td>\n",
       "      <td>[0.0, 0.536170212765957, 0.014388489208633, 0....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 125], [0, 63, 0, ...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3500</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.187333</td>\n",
       "      <td>[0.0, 0.9025974025974021, 0.0, 0.1054977711738...</td>\n",
       "      <td>[0.0, 0.8527607361963191, 0.0, 0.9930069930069...</td>\n",
       "      <td>[0.0, 0.8769716088328071, 0.0, 0.1907320349227...</td>\n",
       "      <td>[[0, 0, 0, 125, 0, 0, 0, 0, 0, 0], [0, 139, 0,...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.225333</td>\n",
       "      <td>[0.0, 0.9666666666666661, 0.0, 0.1468459152016...</td>\n",
       "      <td>[0.0, 0.8895705521472391, 0.0, 0.9930069930069...</td>\n",
       "      <td>[0.0, 0.9265175718849841, 0.0, 0.2558558558558...</td>\n",
       "      <td>[[0, 0, 0, 98, 0, 6, 0, 0, 16, 5], [0, 145, 0,...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3500</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.304000</td>\n",
       "      <td>[0.265306122448979, 0.5536332179930791, 0.6000...</td>\n",
       "      <td>[0.10400000000000001, 0.9815950920245391, 0.26...</td>\n",
       "      <td>[0.14942528735632102, 0.707964601769911, 0.363...</td>\n",
       "      <td>[[13, 0, 4, 105, 0, 0, 0, 3, 0, 0], [0, 160, 0...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3500</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.429333</td>\n",
       "      <td>[0.9636363636363631, 0.9006622516556291, 1.0, ...</td>\n",
       "      <td>[0.424, 0.8343558282208581, 0.0144927536231880...</td>\n",
       "      <td>[0.588888888888888, 0.8662420382165601, 0.0285...</td>\n",
       "      <td>[[53, 0, 0, 26, 0, 12, 34, 0, 0, 0], [0, 136, ...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.439333</td>\n",
       "      <td>[0.6740331491712701, 0.8315789473684211, 0.451...</td>\n",
       "      <td>[0.976, 0.9693251533742331, 0.8768115942028981...</td>\n",
       "      <td>[0.7973856209150321, 0.895184135977337, 0.5960...</td>\n",
       "      <td>[[122, 0, 0, 0, 0, 3, 0, 0, 0, 0], [0, 158, 1,...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.494667</td>\n",
       "      <td>[0.7851851851851851, 0.404580152671755, 0.3324...</td>\n",
       "      <td>[0.848, 0.9754601226993861, 0.884057971014492,...</td>\n",
       "      <td>[0.815384615384615, 0.571942446043165, 0.48316...</td>\n",
       "      <td>[[106, 1, 15, 0, 1, 1, 1, 0, 0, 0], [0, 159, 4...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.498667</td>\n",
       "      <td>[0.6205128205128201, 0.4, 0.49275362318840504,...</td>\n",
       "      <td>[0.968, 0.9815950920245391, 0.7391304347826081...</td>\n",
       "      <td>[0.7562500000000001, 0.568383658969804, 0.5913...</td>\n",
       "      <td>[[121, 0, 2, 1, 0, 0, 0, 0, 0, 1], [0, 160, 1,...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3500</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy_score                                    precision_score   \n",
       "26        0.100667  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.100...  \\\n",
       "14        0.132667  [0.0, 1.0, 0.095899930507296, 0.0, 0.0, 0.0, 0...   \n",
       "35        0.137333  [0.0, 0.875, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2         0.187333  [0.0, 0.9025974025974021, 0.0, 0.1054977711738...   \n",
       "11        0.225333  [0.0, 0.9666666666666661, 0.0, 0.1468459152016...   \n",
       "23        0.304000  [0.265306122448979, 0.5536332179930791, 0.6000...   \n",
       "25        0.429333  [0.9636363636363631, 0.9006622516556291, 1.0, ...   \n",
       "8         0.439333  [0.6740331491712701, 0.8315789473684211, 0.451...   \n",
       "34        0.494667  [0.7851851851851851, 0.404580152671755, 0.3324...   \n",
       "9         0.498667  [0.6205128205128201, 0.4, 0.49275362318840504,...   \n",
       "\n",
       "                                         recall_score   \n",
       "26  [0.0, 0.0, 0.0, 0.0, 0.0059171597633130004, 0....  \\\n",
       "14  [0.0, 0.37423312883435506, 1.0, 0.0, 0.0, 0.0,...   \n",
       "35  [0.0, 0.386503067484662, 0.007246376811594001,...   \n",
       "2   [0.0, 0.8527607361963191, 0.0, 0.9930069930069...   \n",
       "11  [0.0, 0.8895705521472391, 0.0, 0.9930069930069...   \n",
       "23  [0.10400000000000001, 0.9815950920245391, 0.26...   \n",
       "25  [0.424, 0.8343558282208581, 0.0144927536231880...   \n",
       "8   [0.976, 0.9693251533742331, 0.8768115942028981...   \n",
       "34  [0.848, 0.9754601226993861, 0.884057971014492,...   \n",
       "9   [0.968, 0.9815950920245391, 0.7391304347826081...   \n",
       "\n",
       "                                             f1_score   \n",
       "26  [0.0, 0.0, 0.0, 0.0, 0.011764705882352, 0.0, 0...  \\\n",
       "14  [0.0, 0.5446428571428571, 0.175015852885225, 0...   \n",
       "35  [0.0, 0.536170212765957, 0.014388489208633, 0....   \n",
       "2   [0.0, 0.8769716088328071, 0.0, 0.1907320349227...   \n",
       "11  [0.0, 0.9265175718849841, 0.0, 0.2558558558558...   \n",
       "23  [0.14942528735632102, 0.707964601769911, 0.363...   \n",
       "25  [0.588888888888888, 0.8662420382165601, 0.0285...   \n",
       "8   [0.7973856209150321, 0.895184135977337, 0.5960...   \n",
       "34  [0.815384615384615, 0.571942446043165, 0.48316...   \n",
       "9   [0.7562500000000001, 0.568383658969804, 0.5913...   \n",
       "\n",
       "                                     confusion_matrix  random_state_seed   \n",
       "26  [[0, 0, 0, 0, 0, 0, 0, 0, 125, 0], [0, 0, 0, 0...                 42  \\\n",
       "14  [[0, 0, 125, 0, 0, 0, 0, 0, 0, 0], [0, 61, 102...                 42   \n",
       "35  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 125], [0, 63, 0, ...                 42   \n",
       "2   [[0, 0, 0, 125, 0, 0, 0, 0, 0, 0], [0, 139, 0,...                 42   \n",
       "11  [[0, 0, 0, 98, 0, 6, 0, 0, 16, 5], [0, 145, 0,...                 42   \n",
       "23  [[13, 0, 4, 105, 0, 0, 0, 3, 0, 0], [0, 160, 0...                 42   \n",
       "25  [[53, 0, 0, 26, 0, 12, 34, 0, 0, 0], [0, 136, ...                 42   \n",
       "8   [[122, 0, 0, 0, 0, 3, 0, 0, 0, 0], [0, 158, 1,...                 42   \n",
       "34  [[106, 1, 15, 0, 1, 1, 1, 0, 0, 0], [0, 159, 4...                 42   \n",
       "9   [[121, 0, 2, 1, 0, 0, 0, 0, 0, 1], [0, 160, 1,...                 42   \n",
       "\n",
       "    test_size  batch_size  learning_rate  \n",
       "26        0.3           1           10.0  \n",
       "14        0.3           1           10.0  \n",
       "35        0.3        3500           10.0  \n",
       "2         0.3           1           10.0  \n",
       "11        0.3        3500           10.0  \n",
       "23        0.3        3500           10.0  \n",
       "25        0.3           1            1.0  \n",
       "8         0.3          50           10.0  \n",
       "34        0.3        3500            1.0  \n",
       "9         0.3        3500            0.5  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"data/results.json\")\n",
    "df.nsmallest(n=10, columns=[\"accuracy_score\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com https://www.tensorflow.org/guide/core/mlp_core, Next, rescale the data so that the pixel values of [0,255] fit into the range of [0,1]. This step ensures that the input pixels have similar distributions and helps with training convergence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNIST-MLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
