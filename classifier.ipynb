{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 20:55:46.498683: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.typing as npt\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining constants\n",
    "TEST_SIZE: np.float_ = .3\n",
    "RANDOM_STATE: np.int_ = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  775  776  777  778  \\\n",
       "0    7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1    2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2    1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3    0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4    4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing and handling data\n",
    "data: pd.DataFrame = pd.read_csv(\"data/input/data_tp1\", header=None)\n",
    "data.iloc[:, data.columns != 0] = data.iloc[:, data.columns != 0] / 255\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNIST_MLP(data: npt.NDArray[np.int_], hidden_layer_size: np.int_, batch_size: np.int_, learning_rate: np.int_) -> dict:\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(784,)),\n",
    "        tf.keras.layers.Dense(hidden_layer_size, activation=\"sigmoid\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    input_data: npt.NDArray[np.int_] = data[:, 1:]\n",
    "    labels: npt.NDArray[np.int_] = data[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_data, labels, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    epochs: np.int_ = 10\n",
    "\n",
    "    model_history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=0)\n",
    "\n",
    "    y_pred: npt.NDArray[np.int_] = model.predict(X_test, batch_size=batch_size, verbose=0)\n",
    "    y_pred = y_pred.argmax(axis=-1)\n",
    "\n",
    "    accuracy_score: np.float_ = sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "    precision_score: npt.NDArray[np.float_] = sklearn.metrics.precision_score(y_test, y_pred, average=None, zero_division=0)\n",
    "    recall_score: npt.NDArray[np.float_] = sklearn.metrics.recall_score(y_test, y_pred, average=None, zero_division=0)\n",
    "    f1_score: npt.NDArray[np.float_] = sklearn.metrics.f1_score(y_test, y_pred, average=None)\n",
    "    confusion_matrix: npt.NDArray[np.int_] = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    run_info: dict = {\n",
    "        \"accuracy_score\": accuracy_score,\n",
    "        \"precision_score\": precision_score.tolist(),\n",
    "        \"recall_score\": recall_score.tolist(),\n",
    "        \"f1_score\": f1_score.tolist(),\n",
    "        \"confusion_matrix\": confusion_matrix.tolist(),\n",
    "        \"random_state_seed\": RANDOM_STATE,\n",
    "        \"test_size\": TEST_SIZE,\n",
    "        \"hidden_layer_size\": hidden_layer_size,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"history\": model_history.history\n",
    "    }\n",
    "\n",
    "    return run_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 20:55:48.868794: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-03 20:55:48.869557: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_sizes: npt.NDArray[np.int_] = np.array([(25,), (50,), (100,)])\n",
    "batch_sizes: list[int] = [1, 20, 50, 3500]\n",
    "lerning_rates: npt.NDArray[np.float_] = np.array([0.5, 1.0, 10.0])\n",
    "\n",
    "configurations: list = list(itertools.product(hidden_layer_sizes, batch_sizes, lerning_rates))\n",
    "\n",
    "run_infos: list[dict] = [MNIST_MLP(data=data.to_numpy(), hidden_layer_size=a, batch_size=b, learning_rate=c) for a, b, c in configurations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "  File \"/tmp/ipykernel_57371/4031375013.py\", line 2, in <module>\n",
      "    json.dump([run_info for run_info in run_infos], file, indent=4)\n",
      "    ^^^^\n",
      "NameError: name 'json' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/pygments/styles/__init__.py\", line 78, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 953, in format_exception_as_a_whole\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1004, in get_records\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/pygments/styles/__init__.py\", line 80, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/results.json\", \"a\") as file:\n",
    "    json.dump([run_info for run_info in run_infos], file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "  File \"/tmp/ipykernel_57371/2262362849.py\", line 1, in <module>\n",
      "    df = pd.read_json(\"data/results.json\")\n",
      "         ^^\n",
      "NameError: name 'pd' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/pygments/styles/__init__.py\", line 78, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2102, in showtraceback\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1310, in structured_traceback\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1199, in structured_traceback\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1052, in structured_traceback\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 953, in format_exception_as_a_whole\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1004, in get_records\n",
      "  File \"/home/lfrf/anaconda3/envs/MNIST-MLP/lib/python3.11/site-packages/pygments/styles/__init__.py\", line 80, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"data/results.json\")\n",
    "df.nsmallest(n=10, columns=[\"accuracy_score\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acordo com https://www.tensorflow.org/guide/core/mlp_core, Next, rescale the data so that the pixel values of [0,255] fit into the range of [0,1]. This step ensures that the input pixels have similar distributions and helps with training convergence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNIST-MLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
