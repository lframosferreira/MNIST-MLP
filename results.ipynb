{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_empirical_error_convergence(loss: npt.NDArray[np.float_], nn_config: dict, annotate: bool = False) -> None:\n",
    "    sns.set(style=\"darkgrid\", color_codes=True, rc={\"figure.figsize\": (8, 5)})\n",
    "    ax = sns.lineplot(data=loss, markers=True, marker=\"o\", label=f'{nn_config[\"learning_rate\"]}')\n",
    "    plt.xticks(np.arange(len(loss)))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Convergence of empirical error\")\n",
    "    plt.legend()\n",
    "    if annotate:\n",
    "        for i, j in enumerate(loss):\n",
    "            ax.annotate(str(np.round(j, 3)), xy=(i, j), xytext=(i, j+0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>random_state_seed</th>\n",
       "      <th>test_size</th>\n",
       "      <th>hidden_layer_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.929333</td>\n",
       "      <td>[0.9111111111111111, 0.9470588235294111, 0.907...</td>\n",
       "      <td>[0.984, 0.9877300613496931, 0.9202898550724631...</td>\n",
       "      <td>[0.9461538461538461, 0.966966966966967, 0.9136...</td>\n",
       "      <td>[[123, 0, 0, 0, 0, 0, 0, 0, 2, 0], [0, 161, 0,...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'loss': [0.82942134141922, 0.3543525338172910...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.928000</td>\n",
       "      <td>[0.9389312977099231, 0.9573170731707311, 0.968...</td>\n",
       "      <td>[0.984, 0.9631901840490791, 0.891304347826086,...</td>\n",
       "      <td>[0.9609375000000001, 0.9602446483180421, 0.928...</td>\n",
       "      <td>[[123, 0, 0, 0, 0, 0, 0, 0, 2, 0], [0, 157, 0,...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'loss': [0.8357468843460081, 0.36331853270530...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.919333</td>\n",
       "      <td>[0.9236641221374041, 0.9693251533742331, 0.898...</td>\n",
       "      <td>[0.968, 0.9693251533742331, 0.898550724637681,...</td>\n",
       "      <td>[0.9453124999999991, 0.9693251533742331, 0.898...</td>\n",
       "      <td>[[121, 0, 1, 0, 0, 0, 1, 0, 2, 0], [0, 158, 0,...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'loss': [0.9272853136062621, 0.42916768789291...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.914000</td>\n",
       "      <td>[0.891304347826086, 0.9575757575757571, 0.9270...</td>\n",
       "      <td>[0.984, 0.9693251533742331, 0.9202898550724631...</td>\n",
       "      <td>[0.935361216730037, 0.9634146341463411, 0.9236...</td>\n",
       "      <td>[[123, 0, 0, 0, 0, 1, 0, 0, 1, 0], [0, 158, 0,...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'loss': [1.069212079048156, 0.472264409065246...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.913333</td>\n",
       "      <td>[0.8978102189781021, 0.9461077844311371, 0.946...</td>\n",
       "      <td>[0.984, 0.9693251533742331, 0.898550724637681,...</td>\n",
       "      <td>[0.9389312977099231, 0.9575757575757571, 0.921...</td>\n",
       "      <td>[[123, 0, 0, 0, 0, 1, 0, 0, 1, 0], [0, 158, 0,...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'loss': [1.152988076210022, 0.477073132991790...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.911333</td>\n",
       "      <td>[0.9242424242424241, 0.962962962962962, 0.9136...</td>\n",
       "      <td>[0.976, 0.9570552147239261, 0.9202898550724631...</td>\n",
       "      <td>[0.9494163424124511, 0.9599999999999991, 0.916...</td>\n",
       "      <td>[[122, 0, 0, 0, 0, 2, 0, 0, 1, 0], [0, 156, 0,...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'loss': [0.8276067972183221, 0.37989017367362...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy_score                                    precision_score  \\\n",
       "28        0.929333  [0.9111111111111111, 0.9470588235294111, 0.907...   \n",
       "16        0.928000  [0.9389312977099231, 0.9573170731707311, 0.968...   \n",
       "15        0.919333  [0.9236641221374041, 0.9693251533742331, 0.898...   \n",
       "19        0.914000  [0.891304347826086, 0.9575757575757571, 0.9270...   \n",
       "31        0.913333  [0.8978102189781021, 0.9461077844311371, 0.946...   \n",
       "4         0.911333  [0.9242424242424241, 0.962962962962962, 0.9136...   \n",
       "\n",
       "                                         recall_score  \\\n",
       "28  [0.984, 0.9877300613496931, 0.9202898550724631...   \n",
       "16  [0.984, 0.9631901840490791, 0.891304347826086,...   \n",
       "15  [0.968, 0.9693251533742331, 0.898550724637681,...   \n",
       "19  [0.984, 0.9693251533742331, 0.9202898550724631...   \n",
       "31  [0.984, 0.9693251533742331, 0.898550724637681,...   \n",
       "4   [0.976, 0.9570552147239261, 0.9202898550724631...   \n",
       "\n",
       "                                             f1_score  \\\n",
       "28  [0.9461538461538461, 0.966966966966967, 0.9136...   \n",
       "16  [0.9609375000000001, 0.9602446483180421, 0.928...   \n",
       "15  [0.9453124999999991, 0.9693251533742331, 0.898...   \n",
       "19  [0.935361216730037, 0.9634146341463411, 0.9236...   \n",
       "31  [0.9389312977099231, 0.9575757575757571, 0.921...   \n",
       "4   [0.9494163424124511, 0.9599999999999991, 0.916...   \n",
       "\n",
       "                                     confusion_matrix  random_state_seed  \\\n",
       "28  [[123, 0, 0, 0, 0, 0, 0, 0, 2, 0], [0, 161, 0,...                 42   \n",
       "16  [[123, 0, 0, 0, 0, 0, 0, 0, 2, 0], [0, 157, 0,...                 42   \n",
       "15  [[121, 0, 1, 0, 0, 0, 1, 0, 2, 0], [0, 158, 0,...                 42   \n",
       "19  [[123, 0, 0, 0, 0, 1, 0, 0, 1, 0], [0, 158, 0,...                 42   \n",
       "31  [[123, 0, 0, 0, 0, 1, 0, 0, 1, 0], [0, 158, 0,...                 42   \n",
       "4   [[122, 0, 0, 0, 0, 2, 0, 0, 1, 0], [0, 156, 0,...                 42   \n",
       "\n",
       "    test_size  hidden_layer_size  batch_size  learning_rate  \\\n",
       "28        0.3                100          20            1.0   \n",
       "16        0.3                 50          20            1.0   \n",
       "15        0.3                 50          20            0.5   \n",
       "19        0.3                 50          50            1.0   \n",
       "31        0.3                100          50            1.0   \n",
       "4         0.3                 25          20            1.0   \n",
       "\n",
       "                                              history  \n",
       "28  {'loss': [0.82942134141922, 0.3543525338172910...  \n",
       "16  {'loss': [0.8357468843460081, 0.36331853270530...  \n",
       "15  {'loss': [0.9272853136062621, 0.42916768789291...  \n",
       "19  {'loss': [1.069212079048156, 0.472264409065246...  \n",
       "31  {'loss': [1.152988076210022, 0.477073132991790...  \n",
       "4   {'loss': [0.8276067972183221, 0.37989017367362...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results: pd.DataFrame = pd.read_json(\"data/results.json\")\n",
    "results.nlargest(n=6, columns=[\"accuracy_score\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MNIST-MLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
